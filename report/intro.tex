\section{Introduction}
Named Entity Recognition (NER) is a fundamental task in natural language processing that involves identifying mentions of entities (such as persons, organizations, or in our case, drug names) in unstructured text and classifying them into predefined categories. In the biomedical domain, NER with classification of pharmacological entities is particularly important for text mining applications like drug safety surveillance and automatic extraction of drug--drug interactions. The shared task DDIExtraction 2013 defined a benchmark for this problem, with a subtask focused on recognition and classification of drug names in text~\cite{semeval2013}. For example, given a sentence from a medical article, the goal is to locate all drug mentions and label each as a specific type (e.g., \emph{brand}, \emph{generic drug}, \emph{drug group}, etc.). This combined recognition and classification is often referred to as NERC.

Traditional approaches to NER have used feature-engineered statistical models (such as conditional random fields or perceptron taggers) with orthographic and linguistic features. In a previous phase of this project, a baseline system using classical machine learning was implemented to tag drug names (following a BIO tagging scheme) using a small set of manually crafted features. While such a baseline can achieve reasonable accuracy, it is limited by the completeness of feature engineering. Recent advances in deep learning have shown that neural networks can automatically learn useful features from data. In particular, recurrent neural networks (RNNs) with word embeddings have become state-of-the-art for sequence tagging tasks, including NER, by capturing contextual information and sequential dependencies.

In this report, we describe a neural network solution for the drug name NERC task. Our approach uses a Bidirectional Long Short-Term Memory (BiLSTM) network that takes as input learned word embeddings and additional character-based features in the form of word suffix embeddings. The network produces a sequence of probability distributions over tags for each token, from which the most likely tag sequence is output. We train and evaluate this model on the DDI corpus, which consists of biomedical texts annotated with drug name entities. The best systems in the DDIExtraction 2013 challenge achieved an F1 score of about 71.5\% on this task~\cite{semeval2013}, indicating the difficulty of the problem. Our objective is to approach this performance using a neural architecture, improving upon the earlier feature-based baseline.

According to the task specifications (see provided PDFs), only certain parts of the provided code could be modified. We clearly adhered to these instructions: the data loading and evaluation components were left unchanged, while we focused on implementing and tuning the neural network model definition and training procedure. The rest of this paper is organized as follows. Section 2 describes the dataset and pre-processing. Section 3 details the neural network methodology and the specific architecture used. Section 4 covers experiments and results, including training settings and evaluation metrics. In Section 5, we discuss the results, analyze model errors, and mention potential enhancements. Section 6 concludes the report. 